{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>turn</th>\n",
       "      <th>total_turn</th>\n",
       "      <th>rank</th>\n",
       "      <th>weather</th>\n",
       "      <th>field</th>\n",
       "      <th>condition</th>\n",
       "      <th>p1_side</th>\n",
       "      <th>p1a_form</th>\n",
       "      <th>p1a_hp</th>\n",
       "      <th>...</th>\n",
       "      <th>p2c_status</th>\n",
       "      <th>p2c_tera</th>\n",
       "      <th>p2d_form</th>\n",
       "      <th>p2d_hp</th>\n",
       "      <th>p2d_ability</th>\n",
       "      <th>p2d_item</th>\n",
       "      <th>p2d_move</th>\n",
       "      <th>p2d_status</th>\n",
       "      <th>p2d_tera</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2099996083</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1643.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Psychic Terrain:5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smeargle</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>100</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2099996083</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1643.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Psychic Terrain:4</td>\n",
       "      <td>Trick Room:4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smeargle</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>100</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2099996083</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1643.5</td>\n",
       "      <td>SunnyDay:5</td>\n",
       "      <td>Psychic Terrain:3</td>\n",
       "      <td>Trick Room:3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Torkoal</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>100</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2099996083</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1643.5</td>\n",
       "      <td>SunnyDay:4</td>\n",
       "      <td>Psychic Terrain:2</td>\n",
       "      <td>Trick Room:2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Torkoal</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>fnt</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>100</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2099996083</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1643.5</td>\n",
       "      <td>SunnyDay:3</td>\n",
       "      <td>Psychic Terrain:1</td>\n",
       "      <td>Trick Room:1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Torkoal</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>fnt</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Urshifu</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Wicked Blow:3,Detect:4</td>\n",
       "      <td>fnt</td>\n",
       "      <td>unknown</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    battle_id  turn  total_turn    rank     weather              field  \\\n",
       "0  2099996083     0           5  1643.5         NaN  Psychic Terrain:5   \n",
       "1  2099996083     1           5  1643.5         NaN  Psychic Terrain:4   \n",
       "2  2099996083     2           5  1643.5  SunnyDay:5  Psychic Terrain:3   \n",
       "3  2099996083     3           5  1643.5  SunnyDay:4  Psychic Terrain:2   \n",
       "4  2099996083     4           5  1643.5  SunnyDay:3  Psychic Terrain:1   \n",
       "\n",
       "      condition p1_side  p1a_form  p1a_hp  ... p2c_status p2c_tera p2d_form  \\\n",
       "0           NaN     NaN  Smeargle     100  ...        NaN  unknown  unknown   \n",
       "1  Trick Room:4     NaN  Smeargle       1  ...        NaN  unknown  unknown   \n",
       "2  Trick Room:3     NaN   Torkoal     100  ...        NaN  unknown  unknown   \n",
       "3  Trick Room:2     NaN   Torkoal     100  ...        fnt  unknown  unknown   \n",
       "4  Trick Room:1     NaN   Torkoal      55  ...        fnt  unknown  Urshifu   \n",
       "\n",
       "  p2d_hp p2d_ability p2d_item                p2d_move p2d_status  p2d_tera win  \n",
       "0    100     unknown  unknown                 unknown        NaN   unknown  -1  \n",
       "1    100     unknown  unknown                 unknown        NaN   unknown  -1  \n",
       "2    100     unknown  unknown                 unknown        NaN   unknown  -1  \n",
       "3    100     unknown  unknown                 unknown        NaN   unknown  -1  \n",
       "4      0     unknown  unknown  Wicked Blow:3,Detect:4        fnt   unknown  -1  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# import CSv fi\n",
    "data = pd.read_csv(\"trainingdata02.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10236\\AppData\\Local\\Temp\\ipykernel_14504\\2791707821.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data[col].map(name_to_number)\n",
      "C:\\Users\\10236\\AppData\\Local\\Temp\\ipykernel_14504\\2791707821.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data[col].map(name_to_number)\n",
      "C:\\Users\\10236\\AppData\\Local\\Temp\\ipykernel_14504\\2791707821.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data[col].map(name_to_number)\n",
      "C:\\Users\\10236\\AppData\\Local\\Temp\\ipykernel_14504\\2791707821.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data[col].map(name_to_number)\n",
      "C:\\Users\\10236\\AppData\\Local\\Temp\\ipykernel_14504\\2791707821.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data[col].map(name_to_number)\n",
      "C:\\Users\\10236\\AppData\\Local\\Temp\\ipykernel_14504\\2791707821.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data[col].map(name_to_number)\n",
      "C:\\Users\\10236\\AppData\\Local\\Temp\\ipykernel_14504\\2791707821.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data[col].map(name_to_number)\n",
      "C:\\Users\\10236\\AppData\\Local\\Temp\\ipykernel_14504\\2791707821.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data[col].map(name_to_number)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m y \u001b[38;5;241m=\u001b[39m aggregated_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# 使用分层抽样拆分数据为训练集和测试集\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m     71\u001b[0m X\n",
      "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2583\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2579\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2581\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2583\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2585\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1689\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \n\u001b[0;32m   1661\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1690\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2078\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2076\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2078\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2079\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2080\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2082\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2083\u001b[0m     )\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   2086\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2087\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2088\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2089\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# To filter specific columns.\n",
    "columns_to_keep = [\n",
    "    'battle_id', 'p1a_form', 'p1b_form', 'p1c_form', 'p1d_form',\n",
    "    'p2a_form', 'p2b_form', 'p2c_form', 'p2d_form', 'win'\n",
    "]\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "# To delete rows where the 'win' column is 0.\n",
    "#filtered_data = filtered_data[filtered_data['win'] != 0]\n",
    "\n",
    "# 提取唯一的名字\n",
    "columns_to_encode = [\n",
    "    'p1a_form', 'p1b_form', 'p1c_form', 'p1d_form',\n",
    "    'p2a_form', 'p2b_form', 'p2c_form', 'p2d_form'\n",
    "]\n",
    "unique_names = pd.unique(filtered_data[columns_to_encode].values.ravel('K'))\n",
    "\n",
    "# 为每个名字分配一个唯一的数字\n",
    "name_to_number = {name: idx for idx, name in enumerate(unique_names, start=1)}\n",
    "\n",
    "# 使用字典对列进行编码\n",
    "for col in columns_to_encode:\n",
    "    filtered_data[col] = filtered_data[col].map(name_to_number)\n",
    "\n",
    "# 手动执行聚合\n",
    "# 初始化存储结果的列表\n",
    "battle_ids = []\n",
    "p1_forms = []\n",
    "p2_forms = []\n",
    "wins = []\n",
    "\n",
    "# 遍历分组数据并聚合\n",
    "for battle_id, group in filtered_data.groupby('battle_id'):\n",
    "    battle_ids.append(battle_id)\n",
    "    p1_forms.append(group[['p1a_form', 'p1b_form', 'p1c_form', 'p1d_form']].values.flatten().tolist())\n",
    "    p2_forms.append(group[['p2a_form', 'p2b_form', 'p2c_form', 'p2d_form']].values.flatten().tolist())\n",
    "    wins.append(group['win'].iloc[0])\n",
    "\n",
    "# 创建一个包含聚合数据的新DataFrame\n",
    "aggregated_data = pd.DataFrame({\n",
    "    'battle_id': battle_ids,\n",
    "    'p1_forms': p1_forms,\n",
    "    'p2_forms': p2_forms,\n",
    "    'win': wins\n",
    "})\n",
    "\n",
    "# 定义去重函数\n",
    "def remove_duplicates(forms_list):\n",
    "    return list(dict.fromkeys(forms_list))\n",
    "\n",
    "# 去除p1_forms和p2_forms中的重复项\n",
    "aggregated_data['p1_forms'] = aggregated_data['p1_forms'].apply(remove_duplicates)\n",
    "aggregated_data['p2_forms'] = aggregated_data['p2_forms'].apply(remove_duplicates)\n",
    "\n",
    "# 转换列表列为固定长度的向量，长度不足的用0填充\n",
    "max_length = max(aggregated_data['p1_forms'].apply(len).max(), aggregated_data['p2_forms'].apply(len).max())\n",
    "\n",
    "def pad_list(forms_list, length):\n",
    "    return forms_list + [0] * (length - len(forms_list))\n",
    "\n",
    "aggregated_data['p1_forms'] = aggregated_data['p1_forms'].apply(lambda x: pad_list(x, max_length))\n",
    "aggregated_data['p2_forms'] = aggregated_data['p2_forms'].apply(lambda x: pad_list(x, max_length))\n",
    "\n",
    "# 将特征列转换为向量格式\n",
    "X = pd.concat([pd.DataFrame(aggregated_data['p1_forms'].tolist()), pd.DataFrame(aggregated_data['p2_forms'].tolist())], axis=1)\n",
    "y = aggregated_data['win']\n",
    "\n",
    "# 使用分层抽样拆分数据为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=500, max_depth=100, random_state=100)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report for RandomForestClassifier:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=500, max_depth=100)\n",
    "\n",
    "et.fit(X_train, y_train)\n",
    "y_pred = et.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report for ExtraTreesClassifier:\\n{report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique names\n",
    "columns_to_keep = [\n",
    "    'p1a_form', 'p1b_form', 'p1c_form', 'p1d_form',\n",
    "    'p2a_form', 'p2b_form', 'p2c_form', 'p2d_form'\n",
    "]\n",
    "unique_names = pd.unique(filtered_data[columns_to_encode].values.ravel('K'))\n",
    "\n",
    "# Assign a unique number to each name\n",
    "name_to_number = {name: idx for idx, name in enumerate(unique_names, start=1)}\n",
    "\n",
    "# Encode the columns using the dictionary\n",
    "for col in columns_to_encode:\n",
    "    filtered_data[col] = filtered_data[col].map(name_to_number)\n",
    "\n",
    "# Manually perform aggregation\n",
    "# Initialize lists to store the results\n",
    "battle_ids = []\n",
    "p1_forms = []\n",
    "p2_forms = []\n",
    "wins = []\n",
    "\n",
    "# Iterate over grouped data and aggregate\n",
    "for battle_id, group in filtered_data.groupby('battle_id'):\n",
    "    battle_ids.append(battle_id)\n",
    "    p1_forms.append(group[['p1a_form', 'p1b_form', 'p1c_form', 'p1d_form']].values.flatten().tolist())\n",
    "    p2_forms.append(group[['p2a_form', 'p2b_form', 'p2c_form', 'p2d_form']].values.flatten().tolist())\n",
    "    wins.append(group['win'].iloc[0])\n",
    "\n",
    "# Create a new DataFrame with the aggregated data\n",
    "aggregated_data = pd.DataFrame({\n",
    "    'battle_id': battle_ids,\n",
    "    'p1_forms': p1_forms,\n",
    "    'p2_forms': p2_forms,\n",
    "    'win': wins\n",
    "})\n",
    "\n",
    "# Define a function to remove duplicates\n",
    "def remove_duplicates(forms_list):\n",
    "    return list(dict.fromkeys(forms_list))\n",
    "\n",
    "# Remove duplicates from p1_forms and p2_forms\n",
    "aggregated_data['p1_forms'] = aggregated_data['p1_forms'].apply(remove_duplicates)\n",
    "aggregated_data['p2_forms'] = aggregated_data['p2_forms'].apply(remove_duplicates)\n",
    "\n",
    "# Convert list columns to fixed-length vectors, padding with 0 if necessary\n",
    "max_length = max(aggregated_data['p1_forms'].apply(len).max(), aggregated_data['p2_forms'].apply(len).max())\n",
    "\n",
    "def pad_list(forms_list, length):\n",
    "    return forms_list + [0] * (length - len(forms_list))\n",
    "\n",
    "aggregated_data['p1_forms'] = aggregated_data['p1_forms'].apply(lambda x: pad_list(x, max_length))\n",
    "aggregated_data['p2_forms'] = aggregated_data['p2_forms'].apply(lambda x: pad_list(x, max_length))\n",
    "\n",
    "# Convert feature columns to vector format\n",
    "X = pd.concat([pd.DataFrame(aggregated_data['p1_forms'].tolist()), pd.DataFrame(aggregated_data['p2_forms'].tolist())], axis=1)\n",
    "y = aggregated_data['win']\n",
    "\n",
    "# Split the data into training and testing sets using stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#total turn effact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter specific columns\n",
    "columns_to_keep = [\n",
    "    'battle_id', 'total_turn', 'p1a_form', 'p1b_form', 'p1c_form', 'p1d_form',\n",
    "    'p2a_form', 'p2b_form', 'p2c_form', 'p2d_form', 'win'\n",
    "]\n",
    "filtered_data = data[columns_to_keep]\n",
    "\n",
    "# Delete rows where the 'win' column is 0\n",
    "filtered_data = filtered_data[filtered_data['win'] != 0]\n",
    "\n",
    "# Extract unique names\n",
    "columns_to_encode = [\n",
    "    'p1a_form', 'p1b_form', 'p1c_form', 'p1d_form',\n",
    "    'p2a_form', 'p2b_form', 'p2c_form', 'p2d_form'\n",
    "]\n",
    "unique_names = pd.unique(filtered_data[columns_to_encode].values.ravel('K'))\n",
    "\n",
    "# Assign a unique number to each name\n",
    "name_to_number = {name: idx for idx, name in enumerate(unique_names, start=1)}\n",
    "\n",
    "# Encode the columns using the dictionary\n",
    "for col in columns_to_encode:\n",
    "    filtered_data[col] = filtered_data[col].map(name_to_number)\n",
    "    \n",
    "# Manually perform aggregation\n",
    "# Initialize lists to store the results\n",
    "battle_ids = []\n",
    "p1_forms = []\n",
    "p2_forms = []\n",
    "wins = []\n",
    "total_turns = []\n",
    "\n",
    "# Iterate over grouped data and aggregate\n",
    "for battle_id, group in filtered_data.groupby('battle_id'):\n",
    "    battle_ids.append(battle_id)\n",
    "    total_turns.append(group[['total_turn']].values.flatten().tolist())\n",
    "    p1_forms.append(group[['p1a_form', 'p1b_form', 'p1c_form', 'p1d_form']].values.flatten().tolist())\n",
    "    p2_forms.append(group[['p2a_form', 'p2b_form', 'p2c_form', 'p2d_form']].values.flatten().tolist())\n",
    "    wins.append(group['win'].iloc[0])\n",
    "\n",
    "# Create a new DataFrame with the aggregated data\n",
    "aggregated_data = pd.DataFrame({\n",
    "    'battle_id': battle_ids,\n",
    "    'p1_forms': p1_forms,\n",
    "    'p2_forms': p2_forms,\n",
    "    'win': wins,\n",
    "    'total_turn': total_turns\n",
    "})\n",
    "\n",
    "# Define a function to remove duplicates\n",
    "def remove_duplicates(forms_list):\n",
    "    return list(dict.fromkeys(forms_list))\n",
    "\n",
    "# Remove duplicates from p1_forms and p2_forms\n",
    "aggregated_data['p1_forms'] = aggregated_data['p1_forms'].apply(remove_duplicates)\n",
    "aggregated_data['p2_forms'] = aggregated_data['p2_forms'].apply(remove_duplicates)\n",
    "\n",
    "# Convert list columns to fixed-length vectors, padding with 0 if necessary\n",
    "max_length = max(aggregated_data['p1_forms'].apply(len).max(), aggregated_data['p2_forms'].apply(len).max())\n",
    "\n",
    "def pad_list(forms_list, length):\n",
    "    return forms_list + [0] * (length - len(forms_list))\n",
    "\n",
    "aggregated_data['p1_forms'] = aggregated_data['p1_forms'].apply(lambda x: pad_list(x, max_length))\n",
    "aggregated_data['p2_forms'] = aggregated_data['p2_forms'].apply(lambda x: pad_list(x, max_length))\n",
    "\n",
    "# Convert feature columns to vector format\n",
    "X = pd.concat([pd.DataFrame(aggregated_data['p1_forms'].tolist()), pd.DataFrame(aggregated_data['p2_forms'].tolist())], axis=1)\n",
    "y = aggregated_data['win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data['total_turn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get unique values\n",
    "def get_unique(arr):\n",
    "    return np.unique(arr)\n",
    "\n",
    "# apply to every row of the dataframe\n",
    "aggregated_data['total_turn'] = aggregated_data['total_turn'].apply(get_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([pd.DataFrame(aggregated_data['p1_forms'].tolist()), pd.DataFrame(aggregated_data['p2_forms'].tolist()),pd.DataFrame(aggregated_data['total_turn'].tolist())+len(unique_names)+1], axis=1)\n",
    "Z= pd.concat([pd.DataFrame(aggregated_data['p1_forms'].tolist()), pd.DataFrame(aggregated_data['p2_forms'].tolist()),pd.DataFrame(aggregated_data['total_turn'].tolist())], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=500, max_depth=200, random_state=100)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=500, max_depth=200)\n",
    "\n",
    "et.fit(X_train, y_train)\n",
    "y_pred = et.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
